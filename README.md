# ğŸ’³ AI-Based Financial Fraud Detection System

An end-to-end machine learningâ€“powered fraud detection system built using XGBoost, advanced feature engineering, threshold optimization, explainability techniques, and an interactive Streamlit web application.

This project is designed to be industry-ready, deployment-safe, and interview-defensible.

---

## ğŸš€ Project Highlights

âœ… High-performance XGBoost classifier for fraud detection  
âœ… Handles extreme class imbalance  
âœ… Threshold optimization based on business goals (F1 / Recall trade-offs)  
âœ… Rich visual analytics dashboard  
âœ… Robust model explainability (importance, permutation, PDP)  
âœ… Fully deployed on Streamlit Cloud  

---

## ğŸ§  Problem Statement

Financial fraud detection is a highly imbalanced classification problem where: 

- Fraud cases are extremely rare
- False negatives are very costly
- High recall must be balanced with precision

This system detects fraudulent transactions with:

- Optimized decision threshold
- Interpretable outputs
- Production-grade stability

---

## ğŸ“‚ Dataset

- **Source**: Credit Card Transactions Dataset
- **Records**: ~284,000 transactions
- **Fraud Rate**: ~0.17%
- **Features**:
  - `V1â€“V28`: PCA-transformed features
  - `Time`: Seconds since first transaction
  - `Amount`: Transaction amount
  - `Class`: Target variable (0 = Non-Fraud, 1 = Fraud)

---

## ğŸ›  Feature Engineering

The following additional features are engineered:

| Feature | Description |
|---------|-------------|
| `hour` | Hour of day extracted from Time |
| `day` | Day index extracted from Time |
| `amount_log` | Log-transformed transaction amount |
| `amount_log_scaled` | Standard-scaled log amount |

All features are aligned with the trained model's expected order. 

---

## ğŸ¤– Model Details

- **Algorithm**: XGBoost Classifier
- **Objective**: Binary classification
- **Class Imbalance Handling**: `scale_pos_weight`
- **Evaluation Metrics**:
  - Precision
  - Recall
  - F1 Score
  - ROC-AUC

### ğŸ” Baseline Performance

```
Accuracy : 0.9996
Precision: 0.9205
Recall   : 0.8265
F1 Score : 0.8710
AUC      : 0.9827
```

### ğŸš€ Improved Model (Class Imbalance Aware)

```
Accuracy : 0.9995
Precision: 0.8723
Recall   : 0.8367
F1 Score : 0.8542
AUC      :  0.9838
```

---

## ğŸ¯ Threshold Optimization

Instead of using the default 0.5, thresholds were analyzed using:

- Precisionâ€“Recall curve
- F1 maximization
- Youden's J statistic

### âœ… Final Selected Threshold

```
Threshold = 0.8676844
```

This provides the best trade-off between precision and recall for real-world fraud detection.

---

## ğŸ“Š Streamlit Web Application

### ğŸ”¹ Pages Included

#### 1ï¸âƒ£ Fraud Prediction

- Upload CSV of transactions
- **Outputs**:
  - Fraud probability
  - Binary fraud prediction
  - Downloadable results CSV

#### 2ï¸âƒ£ Visual Analytics

- Fraud vs Non-Fraud distribution
- Hourly & daily fraud trends
- Heatmaps (Day Ã— Hour)
- KDE plots
- Boxplots
- Correlation heatmaps

#### 3ï¸âƒ£ Model Explainability

- XGBoost Gain-based Feature Importance
- Permutation Importance (model-agnostic)
- Manual Partial Dependence Plots (PDP)
- Stable and version-safe
- Shows marginal effect of features

#### 4ï¸âƒ£ Model Performance

- Confusion Matrix
- ROC Curve & AUC
- Precisionâ€“Recall Curve
- Threshold tuning visualization
- Classification Report

#### 5ï¸âƒ£ About Project

- System overview
- Key techniques used

---

## ğŸ” Explainability Strategy

Due to cross-version compatibility issues with SHAP and serialized XGBoost models:

âŒ SHAP disabled (intentionally)  
âœ… Used robust alternatives: 

- Gain-based feature importance
- Permutation importance
- Manual PDP (production-safe)

This ensures no runtime crashes on deployment.

---

## â˜ï¸ Deployment

- **Platform**: Streamlit Cloud
- **Main file**: `streamlit_app.py`
- **Artifacts loaded**: 
  - `fraud_xgb_model.pkl`
  - `fraud_scaler.pkl`

### Run Locally

```bash
pip install -r requirements.txt
streamlit run streamlit_app.py
```

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ streamlit_app.py
â”œâ”€â”€ fraud_xgb_model.pkl
â”œâ”€â”€ fraud_scaler.pkl
â”œâ”€â”€ requirements. txt
â”œâ”€â”€ README.md
```

---

## âš ï¸ Known Warnings (Handled Safely)

- XGBoost version mismatch warnings
- Scikit-learn unpickle version warnings

These do not affect predictions and are safely handled in code.

---

## ğŸ‘¨â€ğŸ’» Author

**Shailendra Bhushan Rai**  
B. Tech Computer Science & Engineering  
Data Scientist / ML Engineer
